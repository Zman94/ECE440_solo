from __future__ import print_function
from copy import deepcopy
from collections import defaultdict
import sys
import time
import math
import pdb

start_time = time.time()

def main():
    if len(sys.argv)!=3:
        print("Not enough arguments.")
        return
    ### Files to train from and save training data ###
    trainingFile = "./movie_review/rt-train.txt"
    testFile = "./movie_review/rt-test.txt"
    # trainingFile = "./fisher_2topic/fisher_train_2topic.txt"
    # testFile = "./fisher_2topic/fisher_test_2topic.txt"
    ### File to write training data to if you want to save it ###
    output_file = "./trainingDocClass.txt"
    ### LaPlace smoothing value ###
    LP = .1
    ### Word list (needs to be converted into a dictionary) ###
    trainVal = list()
    ### 1 or -1 depending on review ###
    docVals = list()
    ### Dictionary of words and their frequency ###
    trainDicts = list()
    ### Trained value list to test based on ###
    trained_network = list()

    read_data(trainingFile, trainVal)
    for x in trainVal:
        docVals.append(int(x[0]))
        del x[0]
    create_dict(trainVal, trainDicts)
    train_network_b(docVals, trainDicts, trained_network, LP)
    write_training(output_file, trained_network)
    ### Get dictionary of values to test on ###
    ### Can reuse variables because our trained_network holds all our data ###
    trainVal = list()
    trainDicts = list()
    docVals = list()
    ### List to hold values generated by system ###
    generated_content = list()
    read_data(testFile, trainVal)
    for x in trainVal:
        docVals.append(int(x[0]))
        del x[0]
    create_dict(trainVal, trainDicts)
    return
    test_values(trainDicts, generated_content, trained_network)
    determine_accuracy(generated_content, docVals)
    # print_odds_ratios(trainedList)
    return

def read_data(input_file, trainVal):
    with open(input_file) as f:
        for line in f:
            line = line.replace("\n", "")
            trainVal.append(line.split(" "))

def create_dict(trainVal, trainDicts):
    runs = 0
    for x in trainVal:
        tempDict = dict()
        for y in x:
            temp = y.split(":")
            tempDict[temp[0]] = int(temp[1])
        trainDicts.append(tempDict)

def train_network_b(docVals, trainDicts, trained_network, LP):
    total = [0, 0]

    ### Set default values = to LP smoothing value ###
    trained_network.append(defaultdict(lambda: LP)) #index 0 is negative reviews
    trained_network.append(defaultdict(lambda: LP)) #index 1 is positive reviews
    for x in range(len(docVals)):
        if docVals[x] < 0:
            total[0]+=1
            for y in trainDicts[x].keys():
                trained_network[0][y]+=1
        else:
            total[1]+=1
            for y in trainDicts[x]:
                trained_network[1][y]+=1

    for i in range(2):
        for y in trained_network[i].iterkeys():
            trained_network[i][y]/=(1.0*(total[i]+LP*2))

    ### set the default value = to 1/number of choices per feature ###
    trained_network[0] = defaultdict(lambda: .5, trained_network[0])
    trained_network[1] = defaultdict(lambda: .5, trained_network[1])

def write_training(output_file, data):
    with open(output_file, 'w') as outfile:
        outfile.write("Training data\n")
        for i in range(2):
            for x in data[i].keys():
                outfile.write(str(x))
            for x in data[i].values():
                outfile.write(str(x))
            outfile.write("\n")

def test_values(trainDicts, generated_content, trained_network):
    probabilities = [0,0] #0 is negative, 1 is positive
    # for x in trainDicts:
    #     print(x)
    # return
    for x in trainDicts:
        for y in x.values():
            print(trained_network[0][y])
            print(trained_network[1][y])
        return
        print(x)
        for i in range(2):
            for y in trained_network[i].keys():
                if y in x.values():
                    probabilities[i]+=math.log(trained_network[i][y])
                else:
                    probabilities[i]+=math.log(1-trained_network[i][y])
        ### Classify Document ###
        if probabilities[0] > probabilities[1]:
            generated_content.append(-1)
        else:
            generated_content.append(1)
        print("probabilities =",probabilities)
        probabilities = [0,0]

def determine_accuracy(generated_content, docVals):
    correct = 0
    total = len(generated_content)
    for i in range(total):
         if generated_content[i] == docVals[i]:
             correct+=1
    print(correct/(1.0*total))

if __name__ == "__main__":
    # pdb.set_trace()
    main()
    print("--- %s seconds ---" % (time.time() - start_time))
